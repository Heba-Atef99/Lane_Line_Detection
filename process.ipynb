{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "from os.path import isfile, join \n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from calibration import calib, undistort\n",
    "from threshold import get_combined_gradients, get_combined_hls, combine_grad_hls\n",
    "from line import Line, get_perspective_transform, get_lane_lines_img, draw_lane, illustrate_info_panel, illustrate_driving_lane_with_topdownview\n",
    "from convert_Pictures_to_video import convert_pictures_to_video "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capture the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_video_path = '/content/input_video/project_video.mp4'\n",
    "challenge_video_path = '/content/input_video/challenge_video.mp4'\n",
    "output_project_vid_path = '/content/project_final_result.mp4'\n",
    "output_challenge_vid_path = '/content/challenge_final_result.mp4'\n",
    "vid_capture = cv2.VideoCapture(project_video_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "th_sobelx, th_sobely, th_mag, th_dir = (30, 100), (30, 100), (70, 100), (np.pi/5, np.pi/2)\n",
    "th_h, th_l, th_s = (39, 100), (0, 60), (100, 255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "while(vid_capture.isOpened()):\n",
    "    # first read the frame\n",
    "    flag, frame = vid_capture.read()\n",
    "\n",
    "    if flag == False:\n",
    "        break\n",
    "    \n",
    "    # path='/content/outputPhoto/frame'+str(i)+'.jpg'\n",
    "    i+=1\n",
    "    \n",
    "    # ****** Stage1: Correcting for Distortion ****** \n",
    "    undist_img = undistort(frame)\n",
    "\n",
    "    # resize frame for faster processing\n",
    "    undist_img = cv2.resize(undist_img, None, fx=1 / 2, fy=1 / 2, interpolation=cv2.INTER_AREA)\n",
    "    rows, cols = undist_img.shape[:2]\n",
    "\n",
    "    # ****** Stage2: Thresholding ****** \n",
    "    combined_gradient = get_combined_gradients(undist_img, th_sobelx, th_sobely, th_mag, th_dir)\n",
    "    combined_hls = get_combined_hls(undist_img, th_h, th_l, th_s)\n",
    "    combined_result = combine_grad_hls(combined_gradient, combined_hls)\n",
    "\n",
    "    cv2.imwrite('content/threshold/frame'+str(i)+'.jpg', combined_result) \n",
    "\n",
    "    c_rows, c_cols = combined_result.shape[:2]\n",
    "    s_LTop2, s_RTop2 = [c_cols / 2 - 24, 5], [c_cols / 2 + 24, 5]\n",
    "    s_LBot2, s_RBot2 = [110, c_rows], [c_cols - 110, c_rows]\n",
    "\n",
    "    src = np.float32([s_LBot2, s_LTop2, s_RTop2, s_RBot2])\n",
    "    dst = np.float32([(170, 720), (170, 0), (550, 0), (550, 720)])\n",
    "\n",
    "    # ****** Stage3: Warped(Bird Eye View) ****** \n",
    "    warp_img, M, Minv = get_perspective_transform(combined_result, src, dst, (720, 720))\n",
    "\n",
    "    # ****** Stage4: Sliding window search  ****** \n",
    "    searching_img = get_lane_lines_img(warp_img, left_line, right_line)\n",
    "    cv2.imwrite('content/search_window/frame'+str(i)+'.jpg', searching_img) \n",
    "\n",
    "\n",
    "    # ****** Stage5: Illustrat lane****** \n",
    "    w_comb_result, w_color_result = draw_lane(searching_img, left_line, right_line)\n",
    "\n",
    "    # Drawing the lines back down onto the road\n",
    "    color_result = cv2.warpPerspective(w_color_result, Minv, (c_cols, c_rows))\n",
    "    lane_color = np.zeros_like(undist_img)\n",
    "    lane_color[220:rows - 12, 0:cols] = color_result\n",
    "\n",
    "    # Combine the result with the original image\n",
    "    result = cv2.addWeighted(undist_img, 1, lane_color, 0.3, 0)\n",
    "\n",
    "    info_panel, birdeye_view_panel = np.zeros_like(result),  np.zeros_like(result)\n",
    "    info_panel[5:110, 5:325] = (255, 255, 255)\n",
    "    birdeye_view_panel[5:110, cols-111:cols-6] = (255, 255, 255)\n",
    "    \n",
    "    info_panel = cv2.addWeighted(result, 1, info_panel, 0.2, 0)\n",
    "    birdeye_view_panel = cv2.addWeighted(info_panel, 1, birdeye_view_panel, 0.2, 0)\n",
    "    road_map = illustrate_driving_lane_with_topdownview(w_color_result, left_line, right_line)\n",
    "    birdeye_view_panel[10:105, cols-106:cols-11] = road_map\n",
    "    birdeye_view_panel = illustrate_info_panel(birdeye_view_panel, left_line, right_line)\n",
    "\n",
    "    cv2.imwrite('content/final/frame'+str(i)+'.jpg', birdeye_view_panel) \n",
    "       \n",
    "    # # test/debug\n",
    "    # cv2.imshow('road info', birdeye_view_panel)\n",
    "    # # out.write(frame)\n",
    "    # if cv2.waitKey(1) & 0xFF == ord('s'):\n",
    "    #     cv2.waitKey(0)\n",
    "    # #if cv2.waitKey(1) & 0xFF == ord('r'):\n",
    "    # #    cv2.imwrite('check1.jpg', undist_img)\n",
    "    # if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "    #     break\n",
    "    \n",
    "vid_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate output video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = ['/content/threshold/', '/content/search_window/', '/content/final/']\n",
    "\n",
    "for dir in directory:\n",
    "    pathIn = dir\n",
    "    pathOut = pathIn + 'output.mp4'\n",
    "    fps = 30\n",
    "    time = 0 # the duration of each picture in the video\n",
    "\n",
    "    convert_pictures_to_video(pathIn, pathOut, fps, time) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottomRight=VideoFileClip(directory[0] + 'output.mp4')\n",
    "bottomLeft=VideoFileClip(directory[1] + 'output.mp4')\n",
    "topRight=VideoFileClip(directory[2] + 'output.mp4')\n",
    "\n",
    "buttom=clips_array([[bottomRight.set_position(200,200), bottomLeft.set_position(200,200)]])\n",
    "result=clips_array([[topRight], [buttom]])\n",
    "#final_clip=clips_array([[top],[buttom]])\n",
    "result.ipython_display(width=600)\n",
    "result.write_videofile(output_project_vid_path)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1aaaa7c69280c2ed6ce15a0f71ab88c632dfba86640f7913ceb1f007d6d1bcf0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('try')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
