{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "import numpy as np\n",
    "import cv2\n",
    "from calibration import undistort\n",
    "from threshold import get_combined_gradients, get_combined_hls, combine_grad_hls\n",
    "from line import Line, get_perspective_transform, get_lane_lines_img, draw_lane, illustrate_info_panel, illustrate_driving_lane_with_topdownview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capture the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_video_path = 'content/input_video/project_video.mp4'\n",
    "challenge_video_path = 'content/input_video/challenge_video.mp4'\n",
    "output_project_vid_path = 'content/project_final_result.mp4'\n",
    "output_challenge_vid_path = 'content/challenge_final_result.mp4'\n",
    "vid_capture = cv2.VideoCapture(project_video_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "th_sobelx, th_sobely, th_mag, th_dir = (30, 100), (30, 100), (70, 100), (np.pi/5, np.pi/2)\n",
    "th_h, th_l, th_s = (39, 100), (0, 60), (100, 255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(frame):\n",
    "    # ****** Stage1: Correcting for Distortion ****** \n",
    "    undist_img = undistort(frame)\n",
    "\n",
    "    # resize frame for faster processing\n",
    "    undist_img = cv2.resize(undist_img, None, fx=1 / 2, fy=1 / 2, interpolation=cv2.INTER_AREA)\n",
    "    rows, cols = undist_img.shape[:2]\n",
    "\n",
    "    # ****** Stage2: Thresholding ****** \n",
    "    combined_gradient = get_combined_gradients(undist_img, th_sobelx, th_sobely, th_mag, th_dir)\n",
    "    combined_hls = get_combined_hls(undist_img, th_h, th_l, th_s)\n",
    "    combined_result = combine_grad_hls(combined_gradient, combined_hls)\n",
    "\n",
    "    c_rows, c_cols = combined_result.shape[:2]\n",
    "    s_LTop2, s_RTop2 = [c_cols / 2 - 24, 5], [c_cols / 2 + 24, 5]\n",
    "    s_LBot2, s_RBot2 = [110, c_rows], [c_cols - 110, c_rows]\n",
    "\n",
    "    src = np.float32([s_LBot2, s_LTop2, s_RTop2, s_RBot2])\n",
    "    dst = np.float32([(170, 720), (170, 0), (550, 0), (550, 720)])\n",
    "\n",
    "    # ****** Stage3: Warped(Bird Eye View) ****** \n",
    "    warp_img, M, Minv = get_perspective_transform(combined_result, src, dst, (720, 720))\n",
    "\n",
    "    # ****** Stage4: Sliding window search  ****** \n",
    "    searching_img = get_lane_lines_img(warp_img, left_line, right_line)\n",
    "\n",
    "    # ****** Stage5: Illustrat lane****** \n",
    "    w_comb_result, w_color_result = draw_lane(searching_img, left_line, right_line)\n",
    "\n",
    "    # Drawing the lines back down onto the road\n",
    "    color_result = cv2.warpPerspective(w_color_result, Minv, (c_cols, c_rows))\n",
    "    lane_color = np.zeros_like(undist_img)\n",
    "    lane_color[220:rows - 12, 0:cols] = color_result\n",
    "\n",
    "    # Combine the result with the original image\n",
    "    result = cv2.addWeighted(undist_img, 1, lane_color, 0.3, 0)\n",
    "\n",
    "    info_panel, birdeye_view_panel = np.zeros_like(result),  np.zeros_like(result)\n",
    "    info_panel[5:110, 5:325] = (255, 255, 255)\n",
    "    birdeye_view_panel[5:110, cols-111:cols-6] = (255, 255, 255)\n",
    "    \n",
    "    info_panel = cv2.addWeighted(result, 1, info_panel, 0.2, 0)\n",
    "    birdeye_view_panel = cv2.addWeighted(info_panel, 1, birdeye_view_panel, 0.2, 0)\n",
    "    road_map = illustrate_driving_lane_with_topdownview(w_color_result, left_line, right_line)\n",
    "    birdeye_view_panel[10:105, cols-106:cols-11] = road_map\n",
    "    birdeye_view_panel = illustrate_info_panel(birdeye_view_panel, left_line, right_line)\n",
    "    combined_result = cv2.cvtColor(combined_result, cv2.COLOR_GRAY2BGR)\n",
    "    combined_result = cv2.resize(combined_result, (searching_img.shape[1], 200))\n",
    "\n",
    "    combined_image = np.vstack([combined_result, searching_img])\n",
    "    combined_image = cv2.resize(combined_image, (300, birdeye_view_panel.shape[0]))\n",
    "    combined_image = np.hstack([birdeye_view_panel, combined_image])\n",
    "    return combined_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate output video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "white_output = output_project_vid_path\n",
    "clip1 = VideoFileClip(project_video_path)\n",
    "white_clip = clip1.fl_image(pro) \n",
    "%time white_clip.write_videofile(white_output, audio=False)   "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1aaaa7c69280c2ed6ce15a0f71ab88c632dfba86640f7913ceb1f007d6d1bcf0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('try')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
